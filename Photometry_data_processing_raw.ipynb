{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katemartian/Photometry_data_processing/blob/master/Photometry_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2KmiZkf79_15"
      },
      "source": [
        "<h1><center>Photometry data processing</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GE1gt_sczfcI"
      },
      "source": [
        "If you want to use this code, please cite our Jove paper:\n",
        "\n",
        "__Martianova, E., Aronson, S., Proulx, C.D.__ [Multi-Fiber Photometry to Record Neural Activity in Freely Moving Animal.](https://www.jove.com/video/60278/multi-fiber-photometry-to-record-neural-activity-freely-moving). _J. Vis. Exp._ (152), e60278, doi:10.3791/60278 (2019)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t0nSz7arOJM"
      },
      "source": [
        "# Set up workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZG_KbLeC3aHM"
      },
      "source": [
        "Run the cell (Shift+Enter or Ctrl+Enter) to mount disk if you work in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FPcmiMMJxVR6"
      },
      "source": [
        "Download photometry_functions.py file from https://github.com/katemartian/Photometry_data_processing and run the following cell \n",
        "\n",
        "OR\n",
        "\n",
        "Run the code cells at the end of the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HTNxMOVjvhf1"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lQs8zH5Bm_d7"
      },
      "outputs": [],
      "source": [
        "# Load necessary module\n",
        "import os\n",
        "import doric as dr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "%matplotlib widget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvlknDFG3WsQ"
      },
      "source": [
        "# Your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pANaPRe1HD9N"
      },
      "source": [
        "Copy our example.csv file from https://github.com/katemartian/Photometry_data_processing \n",
        "\n",
        "OR\n",
        "\n",
        "Use your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "uJ6rDQoN2Sbh",
        "outputId": "a816619b-66ca-4f32-99bf-e1cb8ed4afdc"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 36) (2643324099.py, line 36)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 36\u001b[1;36m\u001b[0m\n\u001b[1;33m    'raw_signal': raw_signal, 'raw_time': raw_time, signal': signal, 'time': time}\u001b[0m\n\u001b[1;37m                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 36)\n"
          ]
        }
      ],
      "source": [
        "metadata = {}\n",
        "metadata['folder'] = ['H:/Data/FB_data/Dopamine/SA95/080223/']\n",
        "metadata['filename'] = ['SA95_080223_NAc_0000']\n",
        "# folder = 'H:/Data/FB_data/Dopamine/SA78/051223/' # Modify it depending on where your file is located\n",
        "# file_name = 'SA78_NAc_051223_0000'   # Change to your data file\n",
        "# folder = 'H:/Data/FB_data/Dopamine/SA78/051523/' # Modify it depending on where your file is located\n",
        "# file_name = 'SA78_DLS_051523_0000'   # Change to your data file\n",
        "# folder = 'H:/Data/FB_data/Dopamine/SA78/051623/' # Modify it depending on where your file is located\n",
        "# file_name = 'SA78_NAc_051623_0001'   # Change to your data file\n",
        "# Folder with your files\n",
        "# folder = 'H:/Data/FB_data/Dopamine/SA77/051923/' # Modify it depending on where your file is located\n",
        "# file_name = 'SA77_DLS_051923_0000'\n",
        "folder = metadata['folder'][0]\n",
        "file_name = metadata['filename'][0]\n",
        "data =[]\n",
        "series = ['Series0001', 'Series0002', 'Series0003']\n",
        "for ser in series:\n",
        "    dio01 = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'DigitalIO','DIO01'])[0]\n",
        "    dio02 = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'DigitalIO','DIO02'])[0]\n",
        "    dio03 = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'DigitalIO','DIO03'])[0]\n",
        "    dio04 = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'DigitalIO','DIO04'])[0]\n",
        "    dio_time = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'DigitalIO','Time'])[0]\n",
        "    infusion = dr.find_event(dio02, dio_time)\n",
        "    front    = dr.find_event(dio03, dio_time)\n",
        "    back     = dr.find_event(dio04, dio_time)\n",
        "    leverRetraction, leverInsertion = dr.detect_edges(dio01, dio_time)\n",
        "    # Load from Channel 2: AOUT01 is reference, AOUT02 is signal\n",
        "    raw_reference = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'AIN02xAOUT01-LockIn','Values'])[0]\n",
        "    raw_signal    = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'AIN02xAOUT02-LockIn','Values'])[0]\n",
        "    raw_time      = dr.h5read(folder + file_name + '.doric',['DataAcquisition','FPConsole','Signals',ser,'AIN02xAOUT02-LockIn','Time'])[0]\n",
        "    # Load processed data\n",
        "    signal        = dr.h5read(folder + file_name + '_DFF.doric',['DataProcessed','FPConsole','DFFSignals',ser,'AIN02xAOUT02-LockIn','Values'])[0]\n",
        "    time          = dr.h5read(folder + file_name + '_DFF.doric',['DataProcessed','FPConsole','DFFSignals',ser,'AIN02xAOUT02-LockIn','Time'])[0]\n",
        "\n",
        "    data_series = {'infusion': infusion, 'front': front, 'back': back, 'leverInsertion': leverInsertion, 'leverRetraction': leverRetraction, 'raw_reference': raw_reference,\n",
        "                'raw_signal': raw_signal, 'raw_time': raw_time, 'signal': signal, 'time': time}\n",
        "    data.append(data_series)\n",
        "\n",
        "# all_data = []\n",
        "# for i in range(len(data)):\n",
        "# \tif i == 0:\n",
        "# \t\tall_data = data[i].copy()\n",
        "# \telse:\n",
        "# \t\tfor key in data[i]:\n",
        "# \t\t\tall_data[key] = np.concatenate((all_data[key], data[i][key]))\n",
        "\n",
        "# data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sS1HiJoa4VgO"
      },
      "source": [
        "Choose from the dataframe calcium dependent and independent signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y4ZXVxId4U8b"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'raw_Time'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m raw_reference \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mraw_reference\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m raw_signal \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mraw_signal\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m raw_time   \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mraw_Time\u001b[39m\u001b[39m'\u001b[39m]\n",
            "\u001b[1;31mKeyError\u001b[0m: 'raw_Time'"
          ]
        }
      ],
      "source": [
        "# Adjust these lines depending on your dataframe\n",
        "raw_reference = data[1]['raw_reference']\n",
        "raw_signal = data[1]['raw_signal']\n",
        "raw_time   = data[1]['raw_Time']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dAZFR4X154YM"
      },
      "source": [
        "Plot the raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "colab_type": "code",
        "id": "M7AqIwke52nn",
        "outputId": "91a258c5-df82-4687-c5b0-389b09c665f0"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 10))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.plot(raw_signal,'blue',linewidth=1.5)\n",
        "ax2 = fig.add_subplot(212)\n",
        "ax2.plot(raw_reference,'purple',linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yKKBDBnNDepn"
      },
      "source": [
        "# Use function get_zdFF to calculate z-dF/F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D7Gclask5pb1"
      },
      "source": [
        "Call the function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4C20fPPX9rQf"
      },
      "source": [
        "# Analysis step by step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fYiYEhiO6A-d"
      },
      "source": [
        "### Smooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove artifacts\n",
        "idx = np.where(raw_reference > 0.1)\n",
        "print(idx)\n",
        "start = idx[0].min()-75\n",
        "stop= idx[0].max()+25\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "plt.plot(raw_signal[start:stop],'blue',linewidth=1.5)\n",
        "plt.plot(raw_reference[start:stop],'purple',linewidth=1.5)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K7MAyaNY9Wtc"
      },
      "outputs": [],
      "source": [
        "smooth_win = 20\n",
        "smooth_reference = smooth_data(raw_reference, smooth_win)\n",
        "smooth_signal = smooth_data(raw_signal, smooth_win)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "colab_type": "code",
        "id": "T9GOc2IrEO-X",
        "outputId": "6bf4b409-7e1a-4982-954e-9e205a5bb11c"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 10))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.plot(smooth_signal,'blue',linewidth=1.5)\n",
        "ax2 = fig.add_subplot(212)\n",
        "ax2.plot(smooth_reference,'purple',linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o-uCAkgtD4_i"
      },
      "source": [
        "### Find the baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vDRcFJYg9cPx"
      },
      "outputs": [],
      "source": [
        "lambd = 5e4 # Adjust lambda to get the best fit\n",
        "porder = 1\n",
        "itermax = 50\n",
        "r_base=airPLS(smooth_reference.T,lambda_=lambd,porder=porder,itermax=itermax)\n",
        "s_base=airPLS(smooth_signal,lambda_=lambd,porder=porder,itermax=itermax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "colab_type": "code",
        "id": "MuHycW6GAxvZ",
        "outputId": "645cf5f2-ed4f-4c8b-f049-fbbf2bfefd4c"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 10))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.plot(smooth_signal,'blue',linewidth=1.5)\n",
        "ax1.plot(s_base,'black',linewidth=1.5)\n",
        "ax2 = fig.add_subplot(212)\n",
        "ax2.plot(smooth_reference,'purple',linewidth=1.5)\n",
        "ax2.plot(r_base,'black',linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r0ilmPz9oaWs"
      },
      "source": [
        "### Remove the baseline and the beginning of the recordings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0s6UNRxUCe6e"
      },
      "outputs": [],
      "source": [
        "remove=200\n",
        "reference = (smooth_reference[remove:] - r_base[remove:])\n",
        "signal = (smooth_signal[remove:] - s_base[remove:])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "colab_type": "code",
        "id": "Np_V9bqLog0R",
        "outputId": "76489cff-1693-4f7c-c711-ce71a993ab8f"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 10))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.plot(signal,'blue',linewidth=1.5)\n",
        "ax2 = fig.add_subplot(212)\n",
        "ax2.plot(reference,'purple',linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oq-87e_UvO9C"
      },
      "source": [
        "### Standardize signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "B-8dMDL7okbs"
      },
      "outputs": [],
      "source": [
        "z_reference = (reference - np.median(reference)) / np.std(reference)\n",
        "z_signal = (signal - np.median(signal)) / np.std(signal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "colab_type": "code",
        "id": "UJcZmKjUv2wJ",
        "outputId": "1044a80e-068e-4fbb-8d47-d0d6efa0433e"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 10))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.plot(z_signal,'blue',linewidth=1.5)\n",
        "ax2 = fig.add_subplot(212)\n",
        "ax2.plot(z_reference,'purple',linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qugBBJnIvLRo"
      },
      "source": [
        "### Fit reference signal to calcium signal using linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8pbF1Z7ZvIJp"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n",
        "            positive=True, random_state=9999, selection='random')\n",
        "n = len(z_reference)\n",
        "lin.fit(z_reference.reshape(n,1), z_signal.reshape(n,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(lin.coef_)\n",
        "print(lin.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "colab_type": "code",
        "id": "vfunk9Y3wirc",
        "outputId": "a56128ac-dea2-4ccb-fb6a-f6cb99721345"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 8))\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax1.plot(z_reference,z_signal,'b.')\n",
        "ax1.plot(z_reference,z_reference_fitted, 'r--',linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YY2tZvF7xDuz"
      },
      "source": [
        "### Align reference to signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SWH5M98HIe3C"
      },
      "outputs": [],
      "source": [
        "z_reference_fitted = lin.predict(z_reference.reshape(n,1)).reshape(n,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "colab_type": "code",
        "id": "ML50ADbLxHAX",
        "outputId": "b6a95ea3-d450-4a20-d0a2-15ca440137f7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 8))\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax1.plot(z_signal,'blue')\n",
        "ax1.plot(z_reference_fitted,'purple')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QfPBVvp7vuG_"
      },
      "source": [
        "### Calculate z-score dF/F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "96_8qNiXvsup"
      },
      "outputs": [],
      "source": [
        "zdFF = (z_signal - z_reference_fitted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "colab_type": "code",
        "id": "f1NYdhV6xY66",
        "outputId": "1f7a509f-e1f1-40e3-a1cb-0184f99d63af"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16, 8))\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax1.plot(zdFF,'black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cQAyfE0-Ne1K"
      },
      "source": [
        "# Contact us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sCpXDrtMNh8R"
      },
      "source": [
        "If you have any questions please contact us: ekaterina.martianova.1@ulaval.ca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lak9o-Hn3QQW"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3H_VRXeUIO70"
      },
      "source": [
        "Run (Shift+Enter or Ctrl+Enter) the following 3 code cells in order to use functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mQObXflHuOxW"
      },
      "source": [
        "## z-score dF/F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Xt2LHpGotWDC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "get_zdFF.py calculates standardized dF/F signal based on calcium-idependent \n",
        "and calcium-dependent signals commonly recorded using fiber photometry calcium imaging\n",
        "\n",
        "Ocober 2019 Ekaterina Martianova ekaterina.martianova.1@ulaval.ca \n",
        "\n",
        "Reference:\n",
        "  (1) Martianova, E., Aronson, S., Proulx, C.D. Multi-Fiber Photometry \n",
        "      to Record Neural Activity in Freely Moving Animal. J. Vis. Exp. \n",
        "      (152), e60278, doi:10.3791/60278 (2019)\n",
        "      https://www.jove.com/video/60278/multi-fiber-photometry-to-record-neural-activity-freely-moving\n",
        "\n",
        "'''\n",
        "\n",
        "def get_zdFF(reference,signal,smooth_win=10,remove=200,lambd=5e4,porder=1,itermax=50): \n",
        "  '''\n",
        "  Calculates z-score dF/F signal based on fiber photometry calcium-idependent \n",
        "  and calcium-dependent signals\n",
        "  \n",
        "  Input\n",
        "      reference: calcium-independent signal (usually 405-420 nm excitation), 1D array\n",
        "      signal: calcium-dependent signal (usually 465-490 nm excitation for \n",
        "                   green fluorescent proteins, or ~560 nm for red), 1D array\n",
        "      smooth_win: window for moving average smooth, integer\n",
        "      remove: the beginning of the traces with a big slope one would like to remove, integer\n",
        "      Inputs for airPLS:\n",
        "      lambd: parameter that can be adjusted by user. The larger lambda is,  \n",
        "              the smoother the resulting background, z\n",
        "      porder: adaptive iteratively reweighted penalized least squares for baseline fitting\n",
        "      itermax: maximum iteration times\n",
        "  Output\n",
        "      zdFF - z-score dF/F, 1D numpy array\n",
        "  '''\n",
        "  \n",
        "  import numpy as np\n",
        "  from sklearn.linear_model import Lasso\n",
        "\n",
        " # Smooth signal\n",
        "  smooth_reference = smooth_signal(reference, smooth_win)\n",
        "  smooth_signal = smooth_signal(signal, smooth_win)\n",
        "  \n",
        " # Remove slope using airPLS algorithm\n",
        "  r_base=airPLS(smooth_reference,lambda_=lambd,porder=porder,itermax=itermax)\n",
        "  s_base=airPLS(smooth_signal,lambda_=lambd,porder=porder,itermax=itermax) \n",
        "\n",
        " # Remove baseline and the begining of recording\n",
        "  smooth_reference = (smooth_reference[remove:] - r_base[remove:])\n",
        "  smooth_signal = (smooth_signal[remove:] - s_base[remove:])   \n",
        "\n",
        " # Standardize signals    \n",
        "  smooth_reference = (smooth_reference - np.median(smooth_reference)) / np.std(smooth_reference)\n",
        "  smooth_signal = (smooth_signal - np.median(smooth_signal)) / np.std(smooth_signal)\n",
        "  \n",
        " # Align reference signal to calcium signal using non-negative robust linear regression\n",
        "  lin = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n",
        "              positive=True, random_state=9999, selection='random')\n",
        "  n = len(smooth_reference)\n",
        "  lin.fit(smooth_reference.reshape(n,1), smooth_signal.reshape(n,1))\n",
        "  smooth_reference = lin.predict(smooth_reference.reshape(n,1)).reshape(n,)\n",
        "\n",
        " # z dFF    \n",
        "  zdFF = (smooth_signal - smooth_reference)\n",
        " \n",
        "  return zdFF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WIBQ4Q1Uxutz"
      },
      "source": [
        "## Smooth signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "V1CrJwf1xt4y"
      },
      "outputs": [],
      "source": [
        "def smooth_data(x,window_len=10,window='flat'):\n",
        "\n",
        "    \"\"\"smooth the data using a window with requested size.\n",
        "    \n",
        "    This method is based on the convolution of a scaled window with the signal.\n",
        "    The signal is prepared by introducing reflected copies of the signal \n",
        "    (with the window size) in both ends so that transient parts are minimized\n",
        "    in the begining and end part of the output signal.\n",
        "    The code taken from: https://scipy-cookbook.readthedocs.io/items/SignalSmooth.html\n",
        "    \n",
        "    input:\n",
        "        x: the input signal \n",
        "        window_len: the dimension of the smoothing window; should be an odd integer\n",
        "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
        "                'flat' window will produce a moving average smoothing.\n",
        "\n",
        "    output:\n",
        "        the smoothed signal        \n",
        "    \"\"\"\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    if x.ndim != 1:\n",
        "        raise(ValueError, \"smooth only accepts 1 dimension arrays.\")\n",
        "\n",
        "    if x.size < window_len:\n",
        "        raise(ValueError, \"Input vector needs to be bigger than window size.\")\n",
        "\n",
        "    if window_len<3:\n",
        "        return x\n",
        "\n",
        "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
        "        raise(ValueError, \"Window is one of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
        "\n",
        "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
        "\n",
        "    if window == 'flat': # Moving average\n",
        "        w=np.ones(window_len,'d')\n",
        "    else:\n",
        "        w=eval('np.'+window+'(window_len)')\n",
        "\n",
        "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
        "\n",
        "    return y[(int(window_len/2)-1):-int(window_len/2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKnY0hyitk_v"
      },
      "source": [
        "## airPLS algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S69QlST55iq4"
      },
      "source": [
        "Original code of airPLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l8re-Cp2tp4R"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "airPLS.py Copyright 2014 Renato Lombardo - renato.lombardo@unipa.it\n",
        "Baseline correction using adaptive iteratively reweighted penalized least squares\n",
        "\n",
        "This program is a translation in python of the R source code of airPLS version 2.0\n",
        "by Yizeng Liang and Zhang Zhimin - https://code.google.com/p/airpls\n",
        "\n",
        "Reference:\n",
        "Z.-M. Zhang, S. Chen, and Y.-Z. Liang, Baseline correction using adaptive iteratively \n",
        "reweighted penalized least squares. Analyst 135 (5), 1138-1146 (2010).\n",
        "\n",
        "Description from the original documentation:\n",
        "Baseline drift always blurs or even swamps signals and deteriorates analytical \n",
        "results, particularly in multivariate analysis.  It is necessary to correct baseline \n",
        "drift to perform further data analysis. Simple or modified polynomial fitting has \n",
        "been found to be effective in some extent. However, this method requires user \n",
        "intervention and prone to variability especially in low signal-to-noise ratio \n",
        "environments. The proposed adaptive iteratively reweighted Penalized Least Squares\n",
        "(airPLS) algorithm doesn't require any user intervention and prior information, \n",
        "such as detected peaks. It iteratively changes weights of sum squares errors (SSE) \n",
        "between the fitted baseline and original signals, and the weights of SSE are obtained \n",
        "adaptively using between previously fitted baseline and original signals. This \n",
        "baseline estimator is general, fast and flexible in fitting baseline.\n",
        "\n",
        "\n",
        "LICENCE\n",
        "This program is free software: you can redistribute it and/or modify\n",
        "it under the terms of the GNU Lesser General Public License as published by\n",
        "the Free Software Foundation, either version 3 of the License, or\n",
        "(at your option) any later version.\n",
        "\n",
        "This program is distributed in the hope that it will be useful,\n",
        "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "GNU Lesser General Public License for more details.\n",
        "\n",
        "You should have received a copy of the GNU Lesser General Public License\n",
        "along with this program.  If not, see <http://www.gnu.org/licenses/>\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csc_matrix, eye, diags\n",
        "from scipy.sparse.linalg import spsolve\n",
        "\n",
        "def WhittakerSmooth(x,w,lambda_,differences=1):\n",
        "    '''\n",
        "    Penalized least squares algorithm for background fitting\n",
        "    \n",
        "    input\n",
        "        x: input data (i.e. chromatogram of spectrum)\n",
        "        w: binary masks (value of the mask is zero if a point belongs to peaks and one otherwise)\n",
        "        lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background\n",
        "        differences: integer indicating the order of the difference of penalties\n",
        "    \n",
        "    output\n",
        "        the fitted background vector\n",
        "    '''\n",
        "    X=np.matrix(x)\n",
        "    m=X.size\n",
        "    i=np.arange(0,m)\n",
        "    E=eye(m,format='csc')\n",
        "    D=E[1:]-E[:-1] # numpy.diff() does not work with sparse matrix. This is a workaround.\n",
        "    W=diags(w,0,shape=(m,m))\n",
        "    A=csc_matrix(W+(lambda_*D.T*D))\n",
        "    B=csc_matrix(W*X.T)\n",
        "    background=spsolve(A,B)\n",
        "    return np.array(background)\n",
        "\n",
        "def airPLS(x, lambda_=100, porder=1, itermax=15):\n",
        "    '''\n",
        "    Adaptive iteratively reweighted penalized least squares for baseline fitting\n",
        "    \n",
        "    input\n",
        "        x: input data (i.e. chromatogram of spectrum)\n",
        "        lambda_: parameter that can be adjusted by user. The larger lambda is,\n",
        "                 the smoother the resulting background, z\n",
        "        porder: adaptive iteratively reweighted penalized least squares for baseline fitting\n",
        "    \n",
        "    output\n",
        "        the fitted background vector\n",
        "    '''\n",
        "    m=x.shape[0]\n",
        "    w=np.ones(m)\n",
        "    for i in range(1,itermax+1):\n",
        "        z=WhittakerSmooth(x,w,lambda_, porder)\n",
        "        d=x-z\n",
        "        dssn=np.abs(d[d<0].sum())\n",
        "        if(dssn<0.001*(abs(x)).sum() or i==itermax):\n",
        "            if(i==itermax): print('WARING max iteration reached!')\n",
        "            break\n",
        "        w[d>=0]=0 # d>0 means that this point is part of a peak, so its weight is set to 0 in order to ignore it\n",
        "        w[d<0]=np.exp(i*np.abs(d[d<0])/dssn)\n",
        "        w[0]=np.exp(i*(d[d<0]).max()/dssn) \n",
        "        w[-1]=w[0]\n",
        "    return z\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Lak9o-Hn3QQW",
        "mQObXflHuOxW",
        "WIBQ4Q1Uxutz",
        "cKnY0hyitk_v"
      ],
      "include_colab_link": true,
      "name": "Photometry_data_processing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
